---
title: "tientran0826"
date: 2025-03-15
draft: false
tags: ["spark", "hadoop"]
categories: ["Tutorial"]
title: 'CÃ i Ä‘áº·t vÃ  setup cá»¥m Apache Spark trÃªn Hadoop 3.3 vá»›i VirtualBox'
---

![Demo](/images/setup-spark/1.png)

## 1. Chuáº©n bá»‹ mÃ´i trÆ°á»ng áº£o hoÃ¡
- áº¢o hoÃ¡ mÃ¡y táº¡o cÃ¡c VMs Ä‘á»ƒ giáº£ láº­p cÃ¡c cá»¥m mÃ¡y chá»§
- Tool áº£o hoÃ¡: Oracle Virtual Box  (https://www.virtualbox.org/wiki/Downloads)
- Ubuntu 20.04.6 LTS (https://releases.ubuntu.com/focal/)
### 1.1 Setup mÃ¡y áº£o gá»‘c
- MÃ¡y nÃ y mÃ¬nh cho lÃ m Master, cÃ i Ä‘á»§ cÃ¡c package sau Ä‘Ã³ Clone ra cÃ¡c mÃ¡y phá»¥ sau =)))
- Thao tÃ¡c trá»±c tiáº¿p trÃªn Virtual Box (provip cÃ³ thá»ƒ sá»­ dá»¥ng Vagrant Ä‘á»ƒ auto)
- LÆ°u Ã½ khi táº¡o mÃ¡y áº£o -> Setting apdapter máº¡ng thÃ nh **Host-only** hoáº·c **Bridge** (ko khuyáº¿n khÃ­ch Bridge vÃ¬ ngá»“i cáº¥u hÃ¬nh IP há»“i rá»›t máº¡ng rÃ¡ng chá»‹u)
![Network-Apdapter](/images/setup-spark/2.png)
- Kiá»ƒm tra IP thÃ´ng vá»›i mÃ¡y host

    ```bash
    ip -4 addr show | grep inet
    ```
![your-ip](/images/setup-spark/3.png)
á» Ä‘Ã¢y Ä‘á»‹a chá»‰ Ä‘Æ°á»£c thÃ´ng vá»›i mÃ¡y host lÃ  *192.168.56.102* - CÃ³ cÃ¹ng dÃ£y IP vá»›i mÃ¡y Host (náº¿u mÃ¡y host thÃ¬ kiá»ƒm tra trong /ipconfig) hoáº·c ping trá»±c tiáº¿p tá»« mÃ¡y Host Ä‘áº¿n IP trÃªn.
![ping-vm-ip](/images/setup-spark/4.png)
## 1.2 CÃ i Ä‘áº·t má»™t sá»‘ package chung
### Java
Lá»‡nh cÃ i Ä‘áº·t
```bash
sudo apt-get update
sudo apt-get install openjdk-11-jdk
```
Kiá»ƒm tra cÃ i Ä‘áº·t
```bash
java -version
```
Kiá»ƒm tra path java
```bash
readlink -f $(which java)
```

![java-version](/images/setup-spark/5.png)

Trong Ä‘Ã³ Ä‘Æ°á»ng dáº«n */usr/lib/jvm/java-11-openjdk-amd64/bin/java* lÃ  Ä‘Æ°á»ng dáº«n HOME_PATH cá»§a java -> Nhá»› lÆ°u cÃ¡i nÃ y Ä‘á»ƒ xÃ­u setup.

### Scala
CÃ i Ä‘áº·t scala
```bash
sudo apt-get install scala
```
Check version scala
```bash
scala -version
```

### Apache Spark

=))) Pháº§n chÃ­nh ğŸ¤¡

Truy cáº­p https://spark.apache.org/downloads.html chá»n version phÃ¹ há»£p á»Ÿ Ä‘Ã¢y mÃ¬nh chá»n báº£n prebuild cho Hadoop 3.3 -> Spark phiÃªn báº£n 3.5.5
![Spark-download](/images/setup-spark/6.png)

KÃ©o file vá» báº±ng wget
```bash
wget https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz
```
![wget-spark](/images/setup-spark/7.png)


Giáº£i nÃ©n tá»‡p .tgz vá»›i *spark-3.5.5-bin-hadoop3.tgz* lÃ  táº­p vá»«a kÃ©o
```bash
tar xvf spark-3.5.5-bin-hadoop3.tgz
```

Move folder Ä‘Ã£ giáº£i nÃ©n vÃ o path */usr/local/spark*
```bash
sudo mv spark-3.5.5-bin-hadoop3 /usr/local/spark
```

ThÃªm spark path vÃ o mÃ´i trÆ°á»ng há»‡ thá»‘ng (tÆ°Æ¡ng tá»± set enviroment variables trong Window)
```bash
sudo nano ~/.bashrc
```
Vá»›i file *.bashrc* chá»©a cÃ¡c biáº¿n mÃ´i trÆ°á»ng cá»§a há»‡ thÃ´ng, thÃªm vÃ o file
```
export PATH=$PATH:/usr/local/spark/bin
```
Apply biáº¿n
```bash
source ~/.bashrc
```
Kiá»ƒm tra spark Ä‘Ã£ Ä‘Æ°á»£c thÃªm vÃ o mÃ´i trÆ°á»ng
```bash
which spark-shell
```
![spark-checker](
/images/setup-spark/8.png)

Váº­y ta Ä‘Ã£ setup má»™t sá»‘ thÆ° viá»‡n cáº§n thiáº¿t cho má»™t cá»¥m

## 2. Clone VMs vÃ  thiáº¿t láº­p connection giá»¯a cÃ¡c cá»¥m

![clone-vm](/images/setup-spark/9.png)

Clone VM gá»‘c Ä‘Ã£ Ä‘Æ°á»£c táº¡o á»Ÿ trÃªn thÃ nh cÃ¡c worker, sá»‘ lÆ°á»£ng bao nhiÃªu thÃ¬ tuá»³ theo options ngÆ°á»i dÃ¹ng. á» Ä‘Ã¢y mÃ¬nh clone thÃªm 2 báº£n Ä‘áº·t tÃªn lÃ  Slave1 vÃ  Slave2 vÃ  cá»¥m Ä‘Æ°á»£c setup ban Ä‘áº§u sáº½ lÃ  Master.

### 2.1 Set láº¡i hostname (tuá»³ chá»n)
- á» Ä‘Ã¢y mÃ¬nh set láº¡i hostname Ä‘á»ƒ tiá»‡n quáº£n lÃ½ =)))
- Vá»›i cá»¥m master Ä‘Æ°á»£c hostname lÃ  pd-master
- CÃ¡c cá»¥m worker Ä‘Æ°á»£c hostname lÃ  pd-slave-1 vÃ  pd-slave-2

CÃº phÃ¡p chuyá»ƒn hostname
```bash
sudo nano /hostname
```
```bash
sudo hostnamectl set-hostname pd-master #Tuong tu voi slave-1, slave-2
```
![change-hostname](/images/setup-spark/10.png)
Reboot Ä‘á»ƒ tháº¥y hostname thay Ä‘á»•i
```bash
sudo reboot
```
![hostname](/images/setup-spark/11.png)
Vá»›i pd-master lÃ  hostname má»›i, á»Ÿ Ä‘Ã¢y mÃ¬nh Ä‘á»•i tá»« trÆ°á»›c nÃªn cÃ¡c cÃ¡c lá»‡nh á»Ÿ hÆ°á»›ng dáº«n trÃªn Ä‘á»u máº·c Ä‘á»‹nh lÃ  pd-master 

### 2.2 Add hosts cho master vÃ  slaves

NhÆ° cÃº phÃ¡p kiá»ƒm tra Ä‘á»‹a chá»‰ ip nhÆ° pháº§n 1 Ä‘Ã£ hÆ°á»›ng dáº«n ta láº§n lÆ°á»£t cÃ³ cÃ¡c Ä‘á»‹a chá»‰ nhÆ° sau:
```bash
192.168.56.102 pd-master
192.168.56.103 pd-slave-1
192.168.56.104 pd-slave-2
```

ThÃªm vÃ o file hosts tá»«ng VMs Ä‘á»ƒ chÃºng biáº¿t Ä‘á»‹a chá»‰ phÃ¢n giáº£i khi ta gá»i cÃ¡c mÃ¡y báº±ng hostname

```bash
sudo nano /etc/hosts
```
![input-hosts](/images/setup-spark/12.png)

Save vÃ  kiá»ƒm tra hosts Ä‘Æ°á»£c thÃªm báº±ng cÃ¡ch ping tá»« má»™t VM báº¥t ká»³ Ä‘áº¿n cÃ¡c VMs cÃ²n láº¡i
![ping-hosts](/images/setup-spark/13.png)

## 3. Setup mÃ¡y Master
### 3.1 SSH Ä‘áº¿n Slaves
Config SSH cho mÃ¡y master sá»­ dá»¥ng ssh-keygen Ä‘á»ƒ Ä‘áº·p nháº­p thay vÃ¬ password vÃ¬ lÃ½ do báº£o máº­t + nhanh vÃ  tá»± Ä‘á»™ng hÆ¡n.

CÃ i Ä‘áº·t *Open SSH Server-Client*
```bash
sudo apt-get install openssh-server openssh-client
```
Generate key pairs
```bash
ssh-keygen -t rsa -P ""
```
![keygen-generator](/images/setup-spark/14.png)

Äáº©y key vá»«a táº¡o vÃ o authorized_keys
```bash
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```

ÄÆ°a ssh-keygen vá»«a Ä‘Æ°á»£c táº¡o vÃ o key Ä‘Æ°á»£c truy cáº­p cá»§a cáº£ mÃ¡y master vÃ  cÃ¡c mÃ¡y slaves

```bash
ssh-copy-id user@pd-master #Thay user bang account name
ssh-copy-id user@pd-slave-1
ssh-copy-id user@pd-slave-2
```
Kiá»ƒm tra ssh tá»« mÃ¡y master Ä‘áº¿n cÃ¡c mÃ¡y slaves

```bash
ssh pd-slave-1 # Test ssh den slave 1
ssh pd-slave-2 # Test ssh den slave 2
```

### 3.2 Spark config cho Master
Chuyá»ƒn Ä‘áº¿n thÆ° má»¥c config cá»§a Spark
```bash
cd /usr/local/spark/conf
```
Copy template config cá»§a spark vÃ o cÃ¹ng thÆ° má»¥c
```bash
cp spark-env.sh.template spark-env.sh
```
Giá» lÃ  lÃºc config =)))
```bash
sudo nano spark-env.sh
```
ThÃªm Ä‘oáº¡n nÃ y vÃ o (thay Ä‘á»‹a chá»‰ vÃ  Ä‘Æ°á»ng dáº«n)
```bash
export SPARK_MASTER_HOST='<MASTER-IP>'
export JAVA_HOME=<Path_of_JAVA_installation>
```
Vá»›i MASTER_IP vá»›i mÃ¡y master nhÆ° vÃ­ dá»¥ lÃ  *192.168.56.102* vÃ  JAVA_HOME lÃ  */usr/lib/jvm/java-11-openjdk-amd64/bin/java*.

### 3.3 ThÃªm workers
Trong cÃ¹ng thÆ° má»¥c */usr/local/spark/conf*
```bash
sudo nano slaves
```

ThÃªm ná»™i dung nhÆ° sau

```bash
pd-master
pd-slave-1
pd-slave-2
```
### 3.4 Khá»Ÿi Ä‘á»™ng Spark Cluster
TrÃªn mÃ¡y Master

```bash
cd /usr/local/spark
./sbin/start-all.sh
```
![spark-start](/images/setup-spark/15.png)

Lá»‡nh stop
```bash
./sbin/stop-all.sh
```

## 4. Kiá»ƒm tra cá»¥m Spark
### 4.1 Spark UI
Kiá»ƒm tra thÃ´ng qua Spark UI, tá»« mÃ¡y host hoáº·c trÃªn cÃ¡c VMs truy cáº­p

```
http://<MASTER-IP>:8080/
```

![Spark-UI](/images/setup-spark/16.png)

### 4.2 Check qua code
- LÆ°á»i cÃ i JAVA trÃªn mÃ¡y host quÃ¡ nÃªn mÃ¬nh test code trÃªn mÃ¡y Master luÃ´n.
- Note: Nhá»› cÃ i pyspark =)))

```bash
nano test_spark.py
```

Code demo:
```python
from pyspark.sql import SparkSession
import os

spark = SparkSession.builder\
            .appName("Check Cluster Spark)\
            .master("spark://<MASTER-IP>:7077)\
            .getOrCreate()
data = [("Alice",25)]
df = spark.createDataFrame(data, ["Name", "Age"])
df.show()
# Them cai nay de hoi chay file py trong command khong bi end session ngay lap tuc
input("Inter to exit") 
```
Káº¿t quáº£:
![Demo](/images/setup-spark/1.png)
